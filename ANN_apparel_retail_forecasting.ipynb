{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('retail_data_5.csv',sep=';',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ortalama_SICAKLIK</th>\n",
       "      <th>Toplam_CIROILKFIYAT</th>\n",
       "      <th>Toplam_CIRO</th>\n",
       "      <th>Toplam_Musteri_Sat</th>\n",
       "      <th>Indirim_Yuzdesi</th>\n",
       "      <th>Istinyepark</th>\n",
       "      <th>Akasya</th>\n",
       "      <th>Akbati</th>\n",
       "      <th>Beylikduzu</th>\n",
       "      <th>Brandium</th>\n",
       "      <th>...</th>\n",
       "      <th>Metrocity</th>\n",
       "      <th>Natilus</th>\n",
       "      <th>Starcity</th>\n",
       "      <th>YKM_FORUM_ISTANBUL</th>\n",
       "      <th>YKM_FORUM_MARMARA</th>\n",
       "      <th>Ozel_Gunler</th>\n",
       "      <th>Satis_Normalize</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>17064.0</td>\n",
       "      <td>14298.0</td>\n",
       "      <td>70795.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15907.0</td>\n",
       "      <td>11861.0</td>\n",
       "      <td>33988.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>19947.0</td>\n",
       "      <td>15896.0</td>\n",
       "      <td>52796.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>21254.0</td>\n",
       "      <td>16891.0</td>\n",
       "      <td>57846.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>30062.0</td>\n",
       "      <td>21452.0</td>\n",
       "      <td>66466.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ortalama_SICAKLIK  Toplam_CIROILKFIYAT  Toplam_CIRO  Toplam_Musteri_Sat  \\\n",
       "0                   8.0              17064.0      14298.0             70795.0   \n",
       "1                   8.0              15907.0      11861.0             33988.0   \n",
       "2                  12.0              19947.0      15896.0             52796.0   \n",
       "3                  12.0              21254.0      16891.0             57846.0   \n",
       "4                   4.0              30062.0      21452.0             66466.0   \n",
       "...                 ...                  ...          ...                 ...   \n",
       "1355                NaN                  NaN          NaN                 NaN   \n",
       "1356                NaN                  NaN          NaN                 NaN   \n",
       "1357                NaN                  NaN          NaN                 NaN   \n",
       "1358                NaN                  NaN          NaN                 NaN   \n",
       "1359                NaN                  NaN          NaN                 NaN   \n",
       "\n",
       "      Indirim_Yuzdesi  Istinyepark  Akasya  Akbati  Beylikduzu  Brandium  ...  \\\n",
       "0                16.0          1.0     0.0     0.0         0.0       0.0  ...   \n",
       "1                25.0          1.0     0.0     0.0         0.0       0.0  ...   \n",
       "2                20.0          1.0     0.0     0.0         0.0       0.0  ...   \n",
       "3                21.0          1.0     0.0     0.0         0.0       0.0  ...   \n",
       "4                29.0          1.0     0.0     0.0         0.0       0.0  ...   \n",
       "...               ...          ...     ...     ...         ...       ...  ...   \n",
       "1355              NaN          NaN     NaN     NaN         NaN       NaN  ...   \n",
       "1356              NaN          NaN     NaN     NaN         NaN       NaN  ...   \n",
       "1357              NaN          NaN     NaN     NaN         NaN       NaN  ...   \n",
       "1358              NaN          NaN     NaN     NaN         NaN       NaN  ...   \n",
       "1359              NaN          NaN     NaN     NaN         NaN       NaN  ...   \n",
       "\n",
       "      Metrocity  Natilus  Starcity  YKM_FORUM_ISTANBUL  YKM_FORUM_MARMARA  \\\n",
       "0           0.0      0.0       0.0                 0.0                0.0   \n",
       "1           0.0      0.0       0.0                 0.0                0.0   \n",
       "2           0.0      0.0       0.0                 0.0                0.0   \n",
       "3           0.0      0.0       0.0                 0.0                0.0   \n",
       "4           0.0      0.0       0.0                 0.0                0.0   \n",
       "...         ...      ...       ...                 ...                ...   \n",
       "1355        NaN      NaN       NaN                 NaN                NaN   \n",
       "1356        NaN      NaN       NaN                 NaN                NaN   \n",
       "1357        NaN      NaN       NaN                 NaN                NaN   \n",
       "1358        NaN      NaN       NaN                 NaN                NaN   \n",
       "1359        NaN      NaN       NaN                 NaN                NaN   \n",
       "\n",
       "      Ozel_Gunler  Satis_Normalize  Unnamed: 23  Unnamed: 24  Unnamed: 25  \n",
       "0             1.0              0.0          NaN          NaN          NaN  \n",
       "1             0.0              0.0          NaN          NaN          NaN  \n",
       "2             0.0              0.0          NaN          NaN          NaN  \n",
       "3             0.0              0.0          NaN          NaN          NaN  \n",
       "4             1.0              0.0          NaN          NaN          NaN  \n",
       "...           ...              ...          ...          ...          ...  \n",
       "1355          NaN              NaN          NaN          NaN          NaN  \n",
       "1356          NaN              NaN          NaN          NaN          NaN  \n",
       "1357          NaN              NaN          NaN          NaN          NaN  \n",
       "1358          NaN              NaN          NaN          NaN          NaN  \n",
       "1359          NaN              NaN          NaN          NaN          NaN  \n",
       "\n",
       "[1360 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.0000e+00, 1.7064e+04, 1.4298e+04, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [8.0000e+00, 1.5907e+04, 1.1861e+04, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [1.2000e+01, 1.9947e+04, 1.5896e+04, ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset[:1287,0:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset[:1287,22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25925926, 0.13394616, 0.20831425, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.25925926, 0.12468171, 0.17231242, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.40740741, 0.15703121, 0.23192153, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.66666667, 0.05971846, 0.1111226 , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.66666667, 0.0334465 , 0.06417397, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.59259259, 0.02832183, 0.05365558, ..., 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1287,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X_scale, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 22) (193, 22) (194, 22) (900,) (193,) (194,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the layers of the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([    Dense(132, activation='sigmoid', input_shape=(22,)),    Dense(132, activation='sigmoid'),    Dense(1, activation='sigmoid'),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada ANN'nin level'larını aşamalı olarak tanımlıyoruz. \n",
    "Here, we sequentilally define our ANN model. The first layer has 32 neurons and RElu activation function, and 10 inputs (input neurons) since we have 10 input features. This is a dense layer that means all neurons all fully connected to the ohter layer. The second layer is also dense and has 32 neurons with Relu activation fucntion. Finally the output layer has 1 neuron having a sigmoid activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',   loss='binary_crossentropy'  , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the optimization algortihm (that is sgd) and the loss function that is binary crossentropy, and the metric to track taht is accuracy.. Then we start trainig the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 193 samples\n",
      "Epoch 1/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4416 - accuracy: 0.9989 - val_loss: 0.2777 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.2253 - accuracy: 0.9989 - val_loss: 0.1680 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.1466 - accuracy: 0.9989 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.1079 - accuracy: 0.9989 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0853 - accuracy: 0.9989 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0707 - accuracy: 0.9989 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0605 - accuracy: 0.9989 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "900/900 [==============================] - 0s 56us/step - loss: 0.0530 - accuracy: 0.9989 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0472 - accuracy: 0.9989 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0427 - accuracy: 0.9989 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0391 - accuracy: 0.9989 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0361 - accuracy: 0.9989 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0335 - accuracy: 0.9989 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0314 - accuracy: 0.9989 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0296 - accuracy: 0.9989 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0280 - accuracy: 0.9989 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0266 - accuracy: 0.9989 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0254 - accuracy: 0.9989 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0243 - accuracy: 0.9989 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0234 - accuracy: 0.9989 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0225 - accuracy: 0.9989 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0217 - accuracy: 0.9989 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0210 - accuracy: 0.9989 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0204 - accuracy: 0.9989 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0198 - accuracy: 0.9989 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0192 - accuracy: 0.9989 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0187 - accuracy: 0.9989 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "900/900 [==============================] - 0s 46us/step - loss: 0.0183 - accuracy: 0.9989 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0178 - accuracy: 0.9989 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "900/900 [==============================] - 0s 56us/step - loss: 0.0175 - accuracy: 0.9989 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0171 - accuracy: 0.9989 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0167 - accuracy: 0.9989 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0164 - accuracy: 0.9989 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0161 - accuracy: 0.9989 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "900/900 [==============================] - 0s 46us/step - loss: 0.0158 - accuracy: 0.9989 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "900/900 [==============================] - 0s 62us/step - loss: 0.0156 - accuracy: 0.9989 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0153 - accuracy: 0.9989 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0151 - accuracy: 0.9989 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0149 - accuracy: 0.9989 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0147 - accuracy: 0.9989 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0145 - accuracy: 0.9989 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0143 - accuracy: 0.9989 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0141 - accuracy: 0.9989 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0139 - accuracy: 0.9989 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0138 - accuracy: 0.9989 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0136 - accuracy: 0.9989 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0135 - accuracy: 0.9989 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0133 - accuracy: 0.9989 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0132 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0130 - accuracy: 0.9989 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0129 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0128 - accuracy: 0.9989 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0127 - accuracy: 0.9989 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0126 - accuracy: 0.9989 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "900/900 [==============================] - 0s 56us/step - loss: 0.0125 - accuracy: 0.9989 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0124 - accuracy: 0.9989 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "900/900 [==============================] - 0s 62us/step - loss: 0.0123 - accuracy: 0.9989 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0122 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0121 - accuracy: 0.9989 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0120 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0119 - accuracy: 0.9989 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0119 - accuracy: 0.9989 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0118 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "900/900 [==============================] - 0s 46us/step - loss: 0.0116 - accuracy: 0.9989 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0116 - accuracy: 0.9989 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0113 - accuracy: 0.9989 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0113 - accuracy: 0.9989 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "900/900 [==============================] - 0s 60us/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "900/900 [==============================] - 0s 59us/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0111 - accuracy: 0.9989 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0111 - accuracy: 0.9989 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0110 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0110 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0109 - accuracy: 0.9989 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0109 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0108 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0108 - accuracy: 0.9989 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0104 - accuracy: 0.9989 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0104 - accuracy: 0.9989 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0104 - accuracy: 0.9989 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "900/900 [==============================] - 0s 46us/step - loss: 0.0103 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0103 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0103 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "900/900 [==============================] - 0s 46us/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "900/900 [==============================] - 0s 46us/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.0040 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,  batch_size=132, epochs=100,    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 91us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.032548516969551744, 0.9948453903198242]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
